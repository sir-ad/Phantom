<!doctype html><html data-theme=dark lang=en><head><meta charset=UTF-8><meta content="width=device-width,initial-scale=1.0" name=viewport><title>Installation – Phantom</title><meta content="The invisible force behind every great product" name=description><link href=https://phantom.pm/oat.min.css rel=stylesheet><link href=https://phantom.pm/docs.css rel=stylesheet><body><nav class=sidebar><a class=logo href=https://phantom.pm> <strong>Phantom</strong> </a><ul><li class=section-header>Technical Specs<li><a href=https://phantom.pm/docs/tech/architecture-overview/>Architecture Overview</a><li class=section-header>Providers<li><a href=https://phantom.pm/docs/providers/anthropic/>Anthropic</a><li><a href=https://phantom.pm/docs/providers/gemini/>Gemini</a><li><a href=https://phantom.pm/docs/providers/overview/>Index</a><li><a href=https://phantom.pm/docs/providers/ollama/>Ollama</a><li><a href=https://phantom.pm/docs/providers/openai/>Openai</a><li class=section-header>Features<li><a href=https://phantom.pm/docs/features/agents/>Agents</a><li><a href=https://phantom.pm/docs/features/chat/>Chat</a><li><a href=https://phantom.pm/docs/features/prd/>Prd</a><li><a href=https://phantom.pm/docs/features/simulation/>Simulation</a><li><a href=https://phantom.pm/docs/features/swarm/>Swarm</a><li class=section-header>User Guide<li><a href=https://phantom.pm/docs/user/install/>Install</a><li><a href=https://phantom.pm/docs/user/integrations/>Integrations</a><li><a href=https://phantom.pm/docs/user/modules/>Modules</a><li><a href=https://phantom.pm/docs/user/quickstart/>Quickstart</a><li><a href=https://phantom.pm/docs/user/troubleshooting/>Troubleshooting</a></ul></nav><main class=content><article><h1>Installation</h1><hr><h2 id=sidebar-position-3title-installation>sidebar_position: 3 title: Installation</h2><h1 id=installation>Installation</h1><p>Phantom supports macOS, Linux, and Windows (via WSL2). Choose the method that suits you.<h2 id=one-line-installer-recommended>One-Line Installer (Recommended)</h2><p>Downloads the latest release binary and installs it to your system PATH.<pre><code data-lang=bash>curl -fsSL https://raw.githubusercontent.com/sir-ad/Phantom/main/scripts/install.sh | sh
</code></pre><p><strong>What it does:</strong><ol><li>Detects your OS and architecture (macOS Arm/Intel, Linux x64).<li>Downloads the latest release tarball from GitHub Releases.<li>Extracts the <code>phantom</code> binary to <code>~/.phantom/bin/</code>.<li>Adds <code>~/.phantom/bin</code> to your PATH (via <code>.bashrc</code> / <code>.zshrc</code>).</ol><h3 id=upgrading>Upgrading</h3><pre><code data-lang=bash>curl -fsSL https://raw.githubusercontent.com/sir-ad/Phantom/main/scripts/install.sh | sh -s -- --upgrade
</code></pre><h3 id=uninstalling>Uninstalling</h3><pre><code data-lang=bash>rm -rf ~/.phantom
# Remove the PATH entry from your shell RC file
</code></pre><hr><h2 id=npm-global-install>npm Global Install</h2><p>If you have Node.js 18+ installed:<pre><code data-lang=bash>npm install -g phantom-pm
</code></pre><p>This installs the <code>phantom</code> command globally.<h3 id=upgrading-via-npm>Upgrading via npm</h3><pre><code data-lang=bash>npm update -g phantom-pm
</code></pre><hr><h2 id=docker>Docker</h2><p>For isolated environments or CI/CD pipelines:<pre><code data-lang=bash>docker pull phantompm/phantom:latest
docker run -it \
  -e OPENAI_API_KEY="sk-..." \
  phantompm/phantom:latest
</code></pre><p>To use Ollama from Docker, mount the host’s Ollama socket:<pre><code data-lang=bash>docker run -it \
  --network host \
  phantompm/phantom:latest
</code></pre><hr><h2 id=build-from-source>Build from Source</h2><p>For contributors or custom builds:<pre><code data-lang=bash>git clone https://github.com/sir-ad/Phantom.git
cd phantom
npm install
npm run build
</code></pre><p>Run locally:<pre><code data-lang=bash>node packages/cli/dist/index.js
</code></pre><p>Or link globally:<pre><code data-lang=bash>npm link packages/cli
phantom --version
</code></pre><hr><h2 id=system-requirements>System Requirements</h2><table><thead><tr><th>Requirement<th>Minimum<th>Recommended<tbody><tr><td>Node.js<td>18.0.0<td>20.x LTS<tr><td>RAM<td>512 MB<td>2 GB (for local Ollama models)<tr><td>Disk<td>50 MB<td>500 MB (with Ollama models)<tr><td>OS<td>macOS 12+, Ubuntu 20.04+, WSL2<td>macOS 14+, Ubuntu 22.04+</table><h2 id=post-installation>Post-Installation</h2><p>After installing, configure your AI providers:<pre><code data-lang=bash>phantom config setup
</code></pre><p>This walks you through setting API keys for OpenAI, Anthropic, Gemini, and GitHub OAuth.</article></main><script src=https://phantom.pm/oat.min.js></script>